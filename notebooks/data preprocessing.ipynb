{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the src folder\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"../src\"))\n",
    "\n",
    "# Add src to sys.path\n",
    "sys.path.append(src_path)\n",
    "\n",
    "print(f\"Added {src_path} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import start\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_from_disk\n",
    "\n",
    "load_dotenv('./../settings.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "\n",
    "comet_ml.login(project_name=\"multiclass-text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = start()\n",
    "artifact = experiment.get_artifact(\"news_dataset_hugging_face\")\n",
    "\n",
    "artifact.download(\"./../data/processed/\")\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./../data/processed/news_dataset_hugging_face/\"\n",
    "tokenized_dataset_dict = load_from_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "pre_trained_bert_model = config.pre_trained_bert_model\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "            0: 'Business',\n",
    "            1: 'Science & Technology',\n",
    "            2: 'Entertainment',\n",
    "            3: 'Health',\n",
    "        }\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_dataset_dict[\"train\"].shuffle(seed=SEED).select(range(200))\n",
    "validation_dataset = tokenized_dataset_dict[\"validation\"].shuffle(seed=SEED).select(range(200))\n",
    "test_dataset = tokenized_dataset_dict[\"test\"].shuffle(seed=SEED).select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trained_bert_model)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pre_trained_bert_model, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def get_example(index):\n",
    "    return validation_dataset[index][\"title_prepared\"]\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Computes classification metrics for a multiclass classification task with 4 classes.\n",
    "    \n",
    "    Args:\n",
    "        pred: The predictions from the model containing label_ids and logits.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, F1-score, precision, and recall.\n",
    "    \"\"\"\n",
    "    experiment = comet_ml.get_running_experiment()\n",
    "\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    if experiment:\n",
    "        epoch = int(experiment.curr_epoch) if experiment.curr_epoch is not None else 0\n",
    "        experiment.set_epoch(epoch)\n",
    "        experiment.log_confusion_matrix(\n",
    "            y_true=labels,\n",
    "            y_predicted=preds,\n",
    "            file_name=f\"confusion-matrix-epoch-{epoch}.json\",\n",
    "            labels=[\"Business\", \"Science & Technology\", \"Entertainment\", \"Health\"],\n",
    "            index_to_example_function=get_example,\n",
    "        )\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env COMET_MODE=ONLINE\n",
    "%env COMET_LOG_ASSETS=TRUE\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    seed=SEED,\n",
    "    output_dir=\"./../models\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=10,\n",
    "    save_steps=25,\n",
    "    per_device_train_batch_size=8,\n",
    "    report_to=[\"comet_ml\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ml.get_running_experiment().end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
